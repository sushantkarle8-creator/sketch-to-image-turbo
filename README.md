---
title: Img2img Turbo
emoji: ğŸ‘
colorFrom: indigo
colorTo: gray
sdk: gradio
sdk_version: 5.49.0
app_file: app.py
pinned: false
license: mit
---

Check out the configuration reference at https://huggingface.co/docs/hub/spaces-config-reference

ğŸ¨ Sketch to Image Generator (pix2pix-Turbo + Gradio)

â€œTurning imagination into reality â€” one sketch at a time.â€

This project implements a Sketch-to-Image translation system using pix2pix-turbo, a one-step diffusion-based model proposed by CMU and Adobe researchers.
It can instantly convert hand-drawn sketches into realistic color images with remarkable quality and speed, all through a Gradio interface.

ğŸ§  Project Summary

Goal:
To build an AI application that takes a userâ€™s sketch and generates a detailed, realistic image using the img2img-turbo architecture â€” a fast, adversarially trained one-step diffusion model.

Framework:

pix2pix-turbo â†’ for paired translation (sketch â†’ photo)

CycleGAN-turbo â†’ for unpaired translation (day â†” night, clear â†” rainy, etc.)

Gradio â†’ for an interactive local demo

âš™ï¸ Features

âœ… Convert sketches to high-quality, realistic images
âœ… One-step image translation (fast inference â€” 0.1s on A100 GPU)
âœ… Control output with text prompts for style & diversity
âœ… Launch interactive Gradio demo locally
âœ… Extendable to other tasks like edge-to-image or day-to-night translation

ğŸ§© Model Overview

Paper: One-Step Image Translation with Text-to-Image Models (arXiv:2403.12036)

Authors: Gaurav Parmar, Taesung Park, Srinivasa Narasimhan, Jun-Yan Zhu (CMU + Adobe Research)

Core Idea:
Integrate multiple modules of latent diffusion models into a single, end-to-end network using lightweight LoRA adapters and adversarial training â€” enabling fast, high-fidelity, one-step image translation.

ğŸ—ï¸ Architecture Diagram
[Input Sketch] â†’ [pix2pix-turbo Generator (1-step)] â†’ [Realistic Image Output]
                   â†‘
          Text prompt for style control

ğŸš€ How to Run Locally
1ï¸âƒ£ Clone Repository
git clone https://github.com/jayraj-patil/sketch-to-image-turbo.git
cd sketch-to-image-turbo

2ï¸âƒ£ Environment Setup
# Option 1: Conda
conda env create -f environment.yaml
conda activate img2img-turbo

# Option 2: Virtualenv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

3ï¸âƒ£ Run the Gradio Demo
# Launch Sketch â†’ Image demo
gradio gradio_sketch2image.py


or

# Launch Canny Edge â†’ Image demo
gradio gradio_canny2image.py


Then open the Gradio link in your browser to interact with the model.

4ï¸âƒ£ Example Inference via CLI
python src/inference_paired.py \
--model_name "sketch_to_image_stochastic" \
--input_image "assets/examples/sketch_input.png" \
--gamma 0.4 \
--prompt "a futuristic sci-fi city, cinematic lighting, ultra-realistic" \
--output_dir "outputs"

ğŸ§  Sample Results
Input Sketch	Generated Image
ğŸ± Cat outline	ğŸˆ Realistic colored cat
ğŸŸ Fish sketch	ğŸ  Lifelike underwater fish
ğŸ”ï¸ Mountain outline	ğŸŒ„ Beautiful scenic landscape
ğŸ§° Tech Stack
Category	Tools / Libraries
Language	Python
Model	pix2pix-turbo / CycleGAN-turbo
Framework	PyTorch
Interface	Gradio
Utils	OpenCV, NumPy, PIL
ğŸ§‘â€ğŸ’» Author

Jayraj Patil
ğŸ“ Final Year AIML Student
ğŸ’¡ Passionate about Generative AI, Vision Models & Applied Deep Learning
ğŸ”— LinkedIn

ğŸ“§ [Your Email]

ğŸŒŸ Future Work

Add custom sketch upload + style prompt input

Integrate background enhancement / lighting control

Train on custom paired datasets

Deploy using Hugging Face Spaces

â­ â€œFrom lines to life â€” AI turns sketches into imagination realized.â€

ğŸ§© Optional Files to Include

requirements.txt

torch
torchvision
torchaudio
gradio
opencv-python
Pillow
numpy
tqdm


.gitignore

__pycache__/
venv/
outputs/
*.pth
*.pt
*.ckpt
*.log

